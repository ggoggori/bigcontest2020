{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from matplotlib import font_manager, rc\n",
    "import platform\n",
    "\n",
    "if platform.system() == 'Windows':\n",
    "# 윈도우인 경우\n",
    "    font_name = font_manager.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()\n",
    "    rc('font', family=font_name)\n",
    "else:    \n",
    "# Mac 인 경우\n",
    "    rc('font', family='AppleGothic')\n",
    "    \n",
    "plt.style.use('ggplot')\n",
    "import datetime\n",
    "import os\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. trend_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 네이버 트렌드 랩에서 수집한 데이터\n",
    "* 직접 추가한 대,중,소,브랜드 컬럼에 대한 트렌드를 수집함\n",
    "* https://datalab.naver.com/keyword/trendSearch.naver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trend_data_2_train_min.csv\n",
      "trend_data_2_train_to0from1000.csv\n",
      "trend_data_2_train_to1000from2000.csv\n",
      "trend_data_2_train_to2000from3000.csv\n",
      "trend_data_2_train_to3000from4000.csv\n",
      "trend_data_2_train_세홍4000_5000.csv\n",
      "trend_data_2_train_세홍_2_5000_6000.csv\n"
     ]
    }
   ],
   "source": [
    "# tt라는 리스트에 트렌드 데이터를 추가함\n",
    "tt = []\n",
    "for i in os.listdir():\n",
    "    if i[-3:] == 'csv':\n",
    "        if 'trend_data_2_train' in i:\n",
    "            print(i)\n",
    "            try:\n",
    "                tt.append(pd.read_csv(i,encoding='cp949'))\n",
    "            except:\n",
    "                tt.append(pd.read_csv(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train과 test에 트렌드 데이터를 추가하기 위한 전처리\n",
    "train_trend = pd.read_csv('trend_data_2018_scaled.csv', encoding='cp949')\n",
    "test_trend = pd.read_csv('trend_data_2019_scaled.csv', encoding='cp949')\n",
    "\n",
    "train_trend = train_trend.set_index('기간').stack().reset_index().rename(columns={'level_1':'item'})\n",
    "test_trend =test_trend.set_index('기간').stack().reset_index().rename(columns={'level_1':'item'})\n",
    "\n",
    "train_trend['기간'] = (pd.to_datetime(train_trend['기간']) + datetime.timedelta(days=365)).apply(lambda x:str(x)[0:10])\n",
    "test_trend['기간'] = (pd.to_datetime(test_trend['기간']) + datetime.timedelta(days=365)).apply(lambda x:str(x)[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train데이터에 item_w_mean,1years_ago_trend 컬럼 추가\n",
    "df = pd.DataFrame()\n",
    "for i in tt:\n",
    "    df = pd.concat([df,i])\n",
    "\n",
    "train = pd.read_csv(r'new_train.csv',index_col=0,encoding='cp949')\n",
    "\n",
    "train['sdsd'] = train['방송일시'].apply(lambda x:str(x)[0:10])\n",
    "\n",
    "train = train.merge(df,left_on=['sdsd','item'],right_on=['날짜','item'],how='left')\n",
    "\n",
    "train = train.merge(train_trend,left_on=['sdsd','item'],right_on=['기간','item'],how='left')\n",
    "\n",
    "train = train.drop(['sdsd','날짜','item_mean','item_total_mean','기간'],axis=1).rename(columns={0:'1years_ago_trend'})\n",
    "\n",
    "train['item_w_mean'] = train['item_w_mean'].fillna(0)\n",
    "train['1years_ago_trend'] = train['1years_ago_trend'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test데이터에 item_w_mean,1years_ago_trend 컬럼 추가\n",
    "\n",
    "df = pd.read_csv('trend_data_2_test.csv',encoding='cp949')\n",
    "test = pd.read_csv(r'new_test.csv',index_col=0,encoding='cp949')\n",
    "\n",
    "test['sdsd'] = test['방송일시'].apply(lambda x:str(x)[0:10])\n",
    "\n",
    "test = test.merge(df,left_on=['sdsd','item'],right_on=['날짜','item'],how='left')\n",
    "\n",
    "test = test.merge(test_trend,left_on=['sdsd','item'],right_on=['기간','item'],how='left')\n",
    "\n",
    "test = test.drop(['sdsd','날짜','item_mean','item_total_mean','기간'],axis=1).rename(columns={0:'1years_ago_trend'})\n",
    "\n",
    "test['1years_ago_trend'] = test['1years_ago_trend'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 전력 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* kpx에서 수집한 전력데이터를 추가함\n",
    "* smp와 가격결정발전계획용 수요예측데이터를 추가함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://www.kpx.or.kr/www/contents.do?key=223\n",
    "* https://www.kpx.or.kr/www/contents.do?key=225"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "elc_train = pd.read_excel(r'bidforecastgen_land_2019.xls',header=3)\n",
    "elc_test = pd.read_excel(r'bidforecastgen_land_2020.xls',header=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 가격결정발전계획용 수요예측데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([elc_train,elc_test])\n",
    "\n",
    "elc_df = pd.melt(df,id_vars='구분')\n",
    "\n",
    "elc_df['variable'] = elc_df['variable'].apply(lambda x:'0'+str(x) if len(str(x))==1 else x)\n",
    "\n",
    "elc_df['구분'] = elc_df['구분'].astype('str')\n",
    "elc_df['variable'] = elc_df['variable'].astype('str')\n",
    "\n",
    "elc_df['구분'] = elc_df['구분'] + elc_df['variable']\n",
    "\n",
    "\n",
    "# 원본데이터에 00시의 데이터가 24시의 데이터로 표현되어 있음\n",
    "# 24시를 다음날 00시의 데이터로 바꾸는 함수\n",
    "def change_0000(x):\n",
    "    tm=x                                \n",
    "    if x[-2:]=='24':\n",
    "        tm = datetime.datetime.strptime(x[:-2],'%Y%m%d')\n",
    "        tm = tm + datetime.timedelta(days=1)\n",
    "        tm = tm.strftime('%Y%m%d') +'00'\n",
    "                                        \n",
    "    return tm\n",
    "\n",
    "\n",
    "elc_df['구분'] = elc_df['구분'].apply(lambda x: change_0000(x))\n",
    "\n",
    "elc_df['구분'] = elc_df['구분'].apply(lambda x: x[0:8] + ' ' +x[8:]+':00:00')\n",
    "\n",
    "elc_df['구분'] = pd.to_datetime(elc_df['구분'])\n",
    "\n",
    "elc_df = elc_df.rename(columns={'value':'forecast_elc_gen'}).drop('variable',axis=1)\n",
    "\n",
    "\n",
    "train['방송일시'] = pd.to_datetime(train['방송일시'])\n",
    "test['방송일시'] = pd.to_datetime(test['방송일시'])\n",
    "\n",
    "train = pd.merge(train, elc_df, left_on = '방송일시',right_on = '구분',how='left').drop('구분',axis=1)\n",
    "\n",
    "test = pd.merge(test, elc_df, left_on = '방송일시',right_on = '구분',how='left').drop('구분',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "elc_train = pd.read_excel(r'smp_land_2019.xls',header=3)\n",
    "elc_test = pd.read_excel(r'smp_land_2020.xls',header=3)\n",
    "\n",
    "df = pd.concat([elc_train,elc_test])\n",
    "\n",
    "df = df.drop(['최대','최소','평균'],axis=1)\n",
    "\n",
    "\n",
    "\n",
    "elc_df = pd.melt(df,id_vars='구분')\n",
    "\n",
    "elc_df['variable'] = elc_df['variable'].apply(lambda x:'0'+str(x) if len(str(x))==1 else x)\n",
    "\n",
    "elc_df['구분'] = elc_df['구분'].astype('str')\n",
    "elc_df['variable'] = elc_df['variable'].astype('str')\n",
    "\n",
    "elc_df['구분'] = elc_df['구분'] + elc_df['variable']\n",
    "\n",
    "\n",
    "# 원본데이터에 00시의 데이터가 24시의 데이터로 표현되어 있음\n",
    "# 24시를 다음날 00시의 데이터로 바꾸는 함수\n",
    "def change_0000(x):\n",
    "    tm=x                                \n",
    "    if x[-2:]=='24':\n",
    "        tm = datetime.datetime.strptime(x[:-2],'%Y%m%d')\n",
    "        tm = tm + datetime.timedelta(days=1)\n",
    "        tm = tm.strftime('%Y%m%d') +'00'\n",
    "                                        \n",
    "    return tm\n",
    "\n",
    "\n",
    "elc_df['구분'] = elc_df['구분'].apply(lambda x: change_0000(x))\n",
    "\n",
    "elc_df['구분'] = elc_df['구분'].apply(lambda x: x[0:8] + ' ' +x[8:]+':00:00')\n",
    "\n",
    "elc_df['구분'] = pd.to_datetime(elc_df['구분'])\n",
    "\n",
    "elc_df = elc_df.rename(columns={'value':'smp'}).drop('variable',axis=1)\n",
    "\n",
    "train = pd.merge(train, elc_df, left_on = '방송일시',right_on = '구분',how='left').drop('구분',axis=1)\n",
    "\n",
    "test = pd.merge(test, elc_df, left_on = '방송일시',right_on = '구분',how='left').drop('구분',axis=1)\n",
    "\n",
    "train['forecast_elc_gen'] = train['forecast_elc_gen'].ffill()\n",
    "\n",
    "train['smp'] = train['smp'].ffill()\n",
    "\n",
    "test['forecast_elc_gen'] = test['forecast_elc_gen'].ffill().bfill()\n",
    "\n",
    "test['smp'] = test['smp'].ffill().bfill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 지하철 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://data.seoul.go.kr/dataList/OA-12921/F/1/datasetView.do _ train\n",
    "* https://www.data.go.kr/data/15060424/fileData.do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_train = pd.read_csv(r'서울교통공사_1~8호선일별역별시간대별승하차인원_2019년.csv',encoding='cp949',header=1)\n",
    "sub_test = pd.read_csv(r'서울교통공사_1_8호선일별역별시간대별승하차인원_202001_202008.csv',encoding='cp949',header=0)\n",
    "\n",
    "sub_train = pd.concat([sub_train,sub_test])\n",
    "\n",
    "sub_train = sub_train.drop(['역명','역번호','호선'],axis=1)\n",
    "\n",
    "sub_train = pd.melt(sub_train, id_vars=['날짜','구분'])\n",
    "\n",
    "sub_train = sub_train.groupby(['날짜','구분','variable']).mean().reset_index()\n",
    "\n",
    "sub_train = sub_train.drop(sub_train[sub_train['variable'] == '합 계'].index)\n",
    "\n",
    "sub_train['variable'] = sub_train['variable'].apply(lambda x: '05' if x == '06시 이전' else ('24' if x=='24시 이후' else (x[0:2]) ))\n",
    "\n",
    "sub_train['날짜'] = sub_train['날짜'] + sub_train['variable']\n",
    "\n",
    "\n",
    "# 원본데이터에 00시의 데이터가 24시의 데이터로 표현되어 있음\n",
    "# 24시를 다음날 00시의 데이터로 바꾸는 함수\n",
    "def change_0000(x):\n",
    "    tm=x                                \n",
    "    if x[-2:]=='24':\n",
    "        tm = datetime.datetime.strptime(x[:-2],'%Y-%m-%d')\n",
    "        tm = tm + datetime.timedelta(days=1)\n",
    "        tm = tm.strftime('%Y-%m-%d') +'00'\n",
    "                                        \n",
    "    return tm\n",
    "\n",
    "sub_train['날짜'] = sub_train['날짜'].apply(lambda x:change_0000(x))\n",
    "\n",
    "sub_train['날짜'] = sub_train['날짜'].apply(lambda x: x[0:10] + ' ' +x[10:]+':00:00')\n",
    "\n",
    "sub_train['날짜'] = pd.to_datetime(sub_train['날짜'])\n",
    "\n",
    "sub_train = sub_train.drop('variable',axis=1)\n",
    "sub_train = sub_train.drop(sub_train[sub_train['구분']=='하차'].index)\n",
    "sub_train = sub_train.drop('구분',axis=1)\n",
    "\n",
    "train['방송일시'] = pd.to_datetime(train['방송일시'])\n",
    "test['방송일시'] = pd.to_datetime(test['방송일시'])\n",
    "\n",
    "train = pd.merge(train, sub_train, left_on = '방송일시',right_on = '날짜',how='left').drop('날짜',axis=1)\n",
    "\n",
    "test = pd.merge(test, sub_train, left_on = '방송일시',right_on = '날짜',how='left').drop('날짜',axis=1)\n",
    "\n",
    "train = train.rename(columns = {'value':'subway'})\n",
    "test = test.rename(columns = {'value':'subway'})\n",
    "\n",
    "train['subway'] = train['subway'].ffill()\n",
    "\n",
    "test['subway'] = test['subway'].ffill().bfill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 날씨데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([train,test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = pd.read_csv(r'weather_df_(all).csv',encoding='cp949',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_df = weather_df.ffill()\n",
    "\n",
    "weather_df['일시'] = pd.to_datetime(weather_df['일시'], format='%Y-%m-%d %H:%M', errors='raise')\n",
    "\n",
    "df = pd.merge(df, weather_df, left_on = \"방송일시\", right_on = \"일시\", how = 'left')\n",
    "df.drop('일시', inplace = True, axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.미세먼지 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://www.airkorea.or.kr/web/last_amb_hour_data?pMENU_NO=123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dust_df = pd.read_csv(r'dust_df.csv',encoding='cp949',index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dust_df['측정일시'] = dust_df['측정일시'].apply(lambda x: pd.to_datetime(x))\n",
    "\n",
    "df = pd.merge(df, dust_df, left_on = '방송일시',right_on = '측정일시',how='left').drop('측정일시',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:,40:] = df.iloc[:,40:].ffill()\n",
    "\n",
    "pm10 = df.iloc[:,40:57].mean(axis=1)\n",
    "pm25 = df.iloc[:,57:].mean(axis=1)\n",
    "\n",
    "df = df.drop(df.iloc[:,40:].columns,axis=1)\n",
    "\n",
    "df['pm10'] = pm10\n",
    "df['pm25'] = pm25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 기본데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* holiday #http://marketdata.krx.co.kr/mdi#document=01100305"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "view = pd.read_excel('viewrating.xlsx',header = 1)\n",
    "view_raw = view.drop(view.index[-1]).copy()\n",
    "holiday = pd.read_excel('holiday.xls',header = 0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 6.1 결측값 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['방송일시'] = pd.to_datetime(df['방송일시'])\n",
    "\n",
    "df['취급액'] = df['취급액'].fillna(0)\n",
    "\n",
    "df['노출(분)'] = df['노출(분)'].ffill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 6.2 날짜 데이터 추가\n",
    "    *    6.2.1 공휴일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday['일자 및 요일'] = holiday['일자 및 요일'].apply(lambda x:pd.to_datetime(x))\n",
    "\n",
    "holi = []\n",
    "for i in holiday['일자 및 요일']:\n",
    "    month = i.month\n",
    "    day = i.day\n",
    "    holi.append(str(month)+str(day))\n",
    "    \n",
    "df['holi'] = df['방송일시'].apply(lambda x: str(x.month)+str(x.day))\n",
    "\n",
    "df['공휴일'] = df['holi'].isin(holi)\n",
    "\n",
    "df.drop('holi',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    * 6.2.2 요일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDayName(x):\n",
    "    daystring = ['월','화','수','목','금','토','일']\n",
    "    return daystring[x.weekday()]\n",
    "\n",
    "df['요일'] = df.방송일시.apply(getDayName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    * 6.2.3 월초, 중, 말"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy()\n",
    "df1['일'] = df['방송일시'].dt.day\n",
    "\n",
    "def choJungMal(x):\n",
    "    if 0 < x <= 10:\n",
    "        return \"월초\"\n",
    "    elif 11 <= x <= 20:\n",
    "        return \"월중\"\n",
    "    else:\n",
    "        return \"월말\"\n",
    "\n",
    "df['초중말'] = df1['일'].apply(choJungMal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    * 6.2.4 월,일,시간"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['month'] = df['방송일시'].apply(lambda x:str(x.month))\n",
    "df['day'] = df['방송일시'].apply(lambda x:str(x.day))\n",
    "df['hour'] = df['방송일시'].apply(lambda x:str(x.hour))\n",
    "df['minute'] = df['방송일시'].apply(lambda x:str(x.minute))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * train, test 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df.iloc[:37372,: ]\n",
    "\n",
    "test = df.iloc[37372:,: ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. train + 시청률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "view = view.drop(view.index[-1])\n",
    "view = view.drop('2019-01-01 to 2019-12-31',axis=1)\n",
    "\n",
    "view = view.set_index('시간대')\n",
    "\n",
    "df_dummie = pd.DataFrame(columns=view.iloc[-120:,:].columns, index=view.iloc[-120:,:].index)\n",
    "\n",
    "view = pd.concat([df_dummie,view])\n",
    "\n",
    "view.iloc[:120,1] = view.iloc[-120:,0]\n",
    "\n",
    "for i in range(len(view.columns)-1):\n",
    "    view.iloc[:120,i+1] = view.iloc[-120:,i]\n",
    "\n",
    "view = view.reset_index()\n",
    "\n",
    "view = view.drop(view.iloc[-120:,:].index)\n",
    "\n",
    "view = view.transpose()\n",
    "\n",
    "view.columns = list(view.iloc[0,:].values)\n",
    "\n",
    "\n",
    "view = view.drop('시간대',axis=0).fillna(0).reset_index()\n",
    "\n",
    "view= view.melt(id_vars ='index')\n",
    "\n",
    "\n",
    "view['index'] = view['index'] + ' '+ view['variable']\n",
    "\n",
    "view = view.drop('variable',axis=1)\n",
    "view['index'] = view['index'].apply(lambda x:pd.to_datetime(x))\n",
    "\n",
    "view1 = view.set_index('index')['value']\n",
    "\n",
    "def f(x):\n",
    "    time = str(x['방송일시'])\n",
    "    time2 = str(x['방송일시'] + datetime.timedelta(minutes=x['노출(분)']-1))\n",
    "    return view1[time:time2].mean()\n",
    "\n",
    "train['시청률'] = train.apply(f,axis=1)\n",
    "\n",
    "test = test.reset_index().drop('index',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. data export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('train_after_processing_weatheropt3.csv',encoding='cp949')\n",
    "test.to_csv('test_after_processing_weatheropt3.csv',encoding='cp949')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
